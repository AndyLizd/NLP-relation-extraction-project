{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVVNPbdar9KB"
   },
   "source": [
    "# NLP Relation Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8iwYiYPE33F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import nltk\n",
    "from io import open\n",
    "from google.colab import files\n",
    "\n",
    "from pdb import set_trace as bk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVESiQcYG1PG"
   },
   "source": [
    "# Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ1P1morFz8z"
   },
   "outputs": [],
   "source": [
    "# Read in SemEval-2010 Task 8 Dataset\n",
    "# https://github.com/sahitya0000/Relation-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oWJWtESmQad",
    "outputId": "3764f935-4691-4efe-cbe0-0f13da48a68d"
   },
   "outputs": [],
   "source": [
    "train_file = './TRAIN_FILE.TXT'\n",
    "\n",
    "with open(train_file, 'r') as file:\n",
    "  lines = [line.strip() for line in file]\n",
    "\n",
    "for index in range(0, len(lines), 4):\n",
    "  components = lines[index].split('\\t')\n",
    "  sentence_num = components[0]\n",
    "  sentence = components[1][1:-1]\n",
    "  label = lines[index+1]\n",
    "  print(sentence)\n",
    "  print(label)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEUDC-il8-IF"
   },
   "outputs": [],
   "source": [
    "pad_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BPbuq0NJqWx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Raw input sample:\n",
    "\n",
    "1\t\"The system as described above has its greatest application in an arrayed <e1>configuration</e1> of antenna <e2>elements</e2>.\"\n",
    "Component-Whole(e2,e1)\n",
    "Comment: Not a collection: there is structure here, organisation.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Zhenda Li: I think we should process the data in a way similar to hw 3\n",
    "# The following is copied from hw 3, I put 'pass' in the methods, but I think you can directly copy \n",
    "# paste them from hw3, if the 'sentence' input are in the same format \n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.num_words = 100 # the vocab size, including the start tags, end tags, padding tags, ... our model will need this\n",
    "    \n",
    "    def get_ids_from_sentence(self, sentence):\n",
    "        pass\n",
    "    \n",
    "    def tokenized_sentence(self, sentence):\n",
    "        pass\n",
    "\n",
    "    def decode_sentence_from_ids(self, sent_ids):\n",
    "        pass\n",
    "\n",
    " \n",
    "#  instantiate \n",
    "vocab = Vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxsxfuh1D7yB"
   },
   "outputs": [],
   "source": [
    "# create torch dataset, copied from hw 3\n",
    "class Relation_Extraction_dataset(Dataset):\n",
    "    \"\"\"Single-Turn version of Cornell Movie Dialog Cropus dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab, device):\n",
    "        pass\n",
    "        \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors\n",
    "    Args:\n",
    "        data: ...\n",
    "    Returns: dict { \"ids\":     (ids_list, e1_list, e2_list, tgts_list), \n",
    "                    \"tokens\":  (tokens_list, e1_list, e2_list, tgts_list), \n",
    "                    \"tensors\": (seqs, e1s, e2s, tgts)}  \n",
    "            seqs: torch int tensor of shape [padded_length, batch_size].\n",
    "            padded_length = length of the longest src sequence from src_ids\n",
    "            e1s: torch int tensor of shape [batch_size]\n",
    "            e2s: torch int tensor of shape [batch_size]\n",
    "            tgts: torch int tensor of shape [batch_size]\n",
    "    \"\"\"\n",
    "    return { \n",
    "            \"ids\": (ids_list, e1_list, e2_list, tgts_list), \n",
    "            \"tokens\":  (tokens_list, e1_list, e2_list, tgts_list), \n",
    "            \"tensors\": (seqs, e1s, e2s, tgts), # for now, this tuple is the most important one\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AY_xS2oqL0-D"
   },
   "outputs": [],
   "source": [
    "# Create the DataLoader for all_conversations\n",
    "dataset = Relation_Extraction_dataset(...)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
    "                               shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP2TqNm6gVLF"
   },
   "source": [
    "# Evaluation given model/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqFDI9T2gbaG"
   },
   "outputs": [],
   "source": [
    "# codes to get F1 score given a model\n",
    "def eval_model():\n",
    "    pass\n",
    "\n",
    "def print_evaluation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4nNiDp_HApr"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJzfX09UHC67"
   },
   "outputs": [],
   "source": [
    "# BiLSTM Relation Classifier\n",
    "# https://www.aclweb.org/anthology/Y15-1009.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74TsUf2IHGfr"
   },
   "outputs": [],
   "source": [
    "# baseline model: pure work embedding, BLSTM\n",
    "\n",
    "class Baseline_BLSTM(nn.Module):\n",
    "    def __init__(self, vocab, emb_dim=300, hidden_dim=300, num_layers=1, dropout=0.2, tgts_dim=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_words = num_words = vocab.num_words\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers            \n",
    "        self.tgts_dim = tgts_dim\n",
    "\n",
    "        # archeture components\n",
    "        self.embed = nn.Embedding(num_words, emb_dim)\n",
    "        self.blstm = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout, bidirectional=True) \n",
    "        self.linear = nn.Linear(4*hidden_dim, tgts_dim) # 4 = 2 * 2, bidirectional and concate, \n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "\n",
    "    def compute_loss(self, seqs, e1s, e2s, tgts):\n",
    "        '''\n",
    "        Args:\n",
    "            seqs: int tensor [padded_length, batch_size]\n",
    "            e1s: int tensor [batch_size]\n",
    "            e2s: int tensor [batch_size]\n",
    "            tgts: int tensor [batch_size]\n",
    "        Returns:\n",
    "            loss: torch scaler\n",
    "        '''\n",
    "        logits = self.forward(seqs, e1s, e2s) # [batch, tgts_dim]\n",
    "        return self.loss_fn(logits, tgts)\n",
    "\n",
    "\n",
    "    def forward(self, seqs, e1s, e2s):\n",
    "        '''\n",
    "        Args:\n",
    "            seqs: int tensor [padded_length, batch_size]\n",
    "            e1s: int tensor [batch_size]\n",
    "            e2s: int tensor [batch_size]\n",
    "        Returns:\n",
    "            logits: tensor []\n",
    "        '''\n",
    "        # Compute a tensor containing the length of each source sequence.\n",
    "        seq_lengths = torch.sum(seqs != pad_id, axis=0).cpu()\n",
    "        batch_size = seqs.size(1)\n",
    "        batch_indices = torch.tensor([i for i in range(batch_size)])\n",
    "\n",
    "        embeddings = self.embed(seqs)\n",
    "        packed = pack_padded_sequence(embeddings, seq_lengths) # enforce_sorted=False\n",
    "\n",
    "        rnn_out, _ = self.blstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(rnn_out) # unpacked: [padded_length, batch, 2*hidden_dim]\n",
    "\n",
    "        e1_hiddens = unpacked[e1s, batch_indices, :] # [batch, 2*hidden_dim]\n",
    "        e2_hiddens = unpacked[e2s, batch_indices, :] # [batch, 2*hidden_dim]\n",
    "\n",
    "        linear_in = torch.cat([e1_hiddens, e2_hiddens], dim=1)\n",
    "        \n",
    "        return self.linear(linear_in) # [batch, tgts_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccSbPKvi4Wol",
    "outputId": "dbd13c22-88d9-48cf-a5ce-5125a4817119"
   },
   "outputs": [],
   "source": [
    "baseline_model = Baseline_BLSTM(vocab, emb_dim=300, hidden_dim=300, num_layers=1, dropout=0.2, tgts_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQUocEmbgES-"
   },
   "outputs": [],
   "source": [
    "# TODO: testing starts here, remove below later\n",
    "fake_padded_length = 21\n",
    "fake_batch_size = 32\n",
    "fake_input = {\n",
    "    'seqs': torch.randint(0, vocab.num_words, (fake_padded_length, fake_batch_size)), \n",
    "    'e1s': torch.randint(0, fake_padded_length, (fake_batch_size, )), \n",
    "    'e2s': torch.randint(0, fake_padded_length, (fake_batch_size, )),\n",
    "    'tgts': torch.randint(0, 10, (fake_batch_size, )),\n",
    "    }\n",
    "\n",
    "fake_out = baseline_model(fake_input['seqs'], fake_input['e1s'], fake_input['e2s'])\n",
    "fake_loss = baseline_model.compute_loss(fake_input['seqs'], fake_input['e1s'], fake_input['e2s'], fake_input['tgts'])\n",
    "\n",
    "print(fake_loss)\n",
    "# TODO: testing ends here, remove above later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9eXkGS545bS"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xd5rfCxz45Ed"
   },
   "outputs": [],
   "source": [
    "# modified from hw 3\n",
    "def train(model, data_loader, num_epochs, model_file, optimizer = None):\n",
    "    if !optimizer: \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    clip = 50.0\n",
    "    for epoch in tqdm.notebook.trange(num_epochs, desc=\"training\", unit=\"epoch\"):\n",
    "        with tqdm.notebook.tqdm(\n",
    "                data_loader,\n",
    "                desc=\"epoch {}\".format(epoch + 1),\n",
    "                unit=\"batch\",\n",
    "                total=len(data_loader)) as batch_iterator:\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for i, batch_data in enumerate(batch_iterator, start=1):\n",
    "                seqs, e1s, e2s, tgts = batch_data[\"tensors\"]\n",
    "                optimizer.zero_grad()\n",
    "                loss = model.compute_loss(seqs, e1s, e2s, tgts)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                # Gradient clipping before taking the step\n",
    "                _ = nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_iterator.set_postfix(mean_loss=total_loss / i, current_loss=loss.item())\n",
    "            \n",
    "            print('total loss: ', total_loss)\n",
    "\n",
    "    # Save the model after training         \n",
    "    torch.save(model.state_dict(), model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_OPg-8Lnuli"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 10\n",
    "model_file = 'baseline_model.pt'\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr = learning_rate)\n",
    "\n",
    "train(baseline_model, data_loader, num_epochs, model_file, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkg6LDqAHISo"
   },
   "source": [
    "# Evaluation with Pretrained Models and OpenIE Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The man took <e1>driver</e1>'s <e2>keys</e2> until the arrival of police, thus preventing him from leaving.\n",
    "Entity-Origin(e2,e1)\n",
    "\n",
    "Another example is the hammered dulcimer, where the <e1>player</e1> holds the <e2>hammers</e2>.\n",
    "Instrument-Agency(e2,e1)\n",
    "\n",
    "The <e1>campus</e1> comprises the most noteworthy <e2>buildings</e2> including the Rector Tower, the Central Library and the University Olympic Stadium used for the 1968 Olympic Games and the 1986 soccer World Cup.\n",
    "Component-Whole(e2,e1)\n",
    "\n",
    "This <e1>generation</e1> of unregenerated <e2>vipers</e2> was still perverse, stiff-necked, and hardened in their iniquity.\n",
    "Member-Collection(e2,e1)\n",
    "\n",
    "In one of the scenes when Robert and Francessca are talking in front of his truck, a reflection of one of the movie set lights is seen on the <e1>hood</e1> of the <e2>truck</e2>.\n",
    "Component-Whole(e1,e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"The man took driver's keys until the arrival of police, thus preventing him from leaving.\"\n",
    "sentence2 = \"Another example is the hammered dulcimer, where the player holds the hammers.\"\n",
    "sentence3 = \"The campus comprises the most noteworthy buildings including the Rector Tower, the Central Library and the University Olympic Stadium used for the 1968 Olympic Games and the 1986 soccer World Cup.\"\n",
    "sentence4 = \"This generation of unregenerated vipers was still perverse, stiff-necked, and hardened in their iniquity.\"\n",
    "sentence5 = \"In one of the scenes when Robert and Francessca are talking in front of his truck, a reflection of one of the movie set lights is seen on the hood of the truck.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpq7f0aPHQTF"
   },
   "source": [
    "### MinIE: Open Information Extraction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CLASSPATH'] = './minie/minie-0.0.1-SNAPSHOT.jar'\n",
    "from miniepy import *\n",
    "\n",
    "minie = MinIE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tThe man took driver's keys until the arrival of police, thus preventing him from leaving.\n",
      "\n",
      "\tEntities: driver, keys\n",
      "\tGold Relation: Instrument-Agency\n",
      "\n",
      "Extracted triples:\n",
      "\t('man', \"took driver 's keys until\", 'arrival of police thus preventing him from leaving')\n",
      "\t('man', \"took driver 's keys until arrival of\", 'police')\n",
      "\t('man', 'be preventing him from', 'leaving')\n",
      "\t('man', 'be preventing', 'him')\n",
      "\t('driver', 'has', 'keys')\n"
     ]
    }
   ],
   "source": [
    "triples = [p.triple for p in minie.get_propositions(sentence1)]\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence1))\n",
    "print('\\tEntities: {}, {}'.format('driver', 'keys'))\n",
    "print('\\tGold Relation: {}\\n'.format('Instrument-Agency'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tAnother example is the hammered dulcimer, where the player holds the hammers.\n",
      "\n",
      "\tEntities: player, hammers\n",
      "\tGold Relation: Entity-Origin\n",
      "\n",
      "Extracted triples:\n",
      "\t('example', 'is', 'hammered dulcimer')\n",
      "\t('player', 'holds hammers', 'hammered dulcimer')\n"
     ]
    }
   ],
   "source": [
    "triples = [p.triple for p in minie.get_propositions(sentence2)]\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence2))\n",
    "print('\\tEntities: {}, {}'.format('player', 'hammers'))\n",
    "print('\\tGold Relation: {}\\n'.format('Entity-Origin'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tThe campus comprises the most noteworthy buildings including the Rector Tower, the Central Library and the University Olympic Stadium used for the 1968 Olympic Games and the 1986 soccer World Cup.\n",
      "\n",
      "\tEntities: campus, buildings\n",
      "\tGold Relation: Component-Whole\n",
      "\n",
      "Extracted triples:\n",
      "\t('most noteworthy buildings including Rector Tower', 'used for', '1968 Olympic Games')\n",
      "\t('most noteworthy buildings including Rector Tower', 'used for', '1986 soccer World Cup')\n",
      "\t('most noteworthy buildings including Central Library', 'used for', '1968 Olympic Games')\n",
      "\t('most noteworthy buildings including Central Library', 'used for', '1986 soccer World Cup')\n",
      "\t('most noteworthy buildings including University Olympic Stadium', 'used for', '1968 Olympic Games')\n",
      "\t('most noteworthy buildings including University Olympic Stadium', 'used for', '1986 soccer World Cup')\n"
     ]
    }
   ],
   "source": [
    "triples = [p.triple for p in minie.get_propositions(sentence3)]\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence3))\n",
    "print('\\tEntities: {}, {}'.format('campus', 'buildings'))\n",
    "print('\\tGold Relation: {}\\n'.format('Component-Whole'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford OpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openie import StanfordOpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /Users/rhythmsyed/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-5ac9ba2e4527465f.props -preload openie\n",
      "Original text:\n",
      "\tThe man took driver's keys until the arrival of police, thus preventing him from leaving.\n",
      "\n",
      "\tEntities: driver, keys\n",
      "\tGold Relation: Instrument-Agency\n",
      "\n",
      "Extracted triples:\n",
      "\t{'subject': 'man', 'relation': 'took', 'object': \"driver 's keys\"}\n",
      "\t{'subject': 'man', 'relation': 'thus preventing', 'object': 'him'}\n",
      "\t{'subject': 'man', 'relation': 'preventing', 'object': 'him'}\n",
      "\t{'subject': 'driver', 'relation': 'has', 'object': 'keys'}\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "with StanfordOpenIE() as client:\n",
    "    for triple in client.annotate(sentence1):\n",
    "        triples.append(triple)\n",
    "        \n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence1))\n",
    "print('\\tEntities: {}, {}'.format('driver', 'keys'))\n",
    "print('\\tGold Relation: {}\\n'.format('Instrument-Agency'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /Users/rhythmsyed/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-70814b10053c4b95.props -preload openie\n",
      "Original text:\n",
      "\tAnother example is the hammered dulcimer, where the player holds the hammers.\n",
      "\n",
      "\tEntities: player, hammers\n",
      "\tGold Relation: Entity-Origin\n",
      "\n",
      "Extracted triples:\n",
      "\t{'subject': 'player', 'relation': 'holds', 'object': 'hammers'}\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "with StanfordOpenIE() as client:\n",
    "    for triple in client.annotate(sentence2):\n",
    "        triples.append(triple)\n",
    "        \n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence2))\n",
    "print('\\tEntities: {}, {}'.format('player', 'hammers'))\n",
    "print('\\tGold Relation: {}\\n'.format('Entity-Origin'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /Users/rhythmsyed/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-dc0f629111cb462a.props -preload openie\n",
      "Original text:\n",
      "\tThe campus comprises the most noteworthy buildings including the Rector Tower, the Central Library and the University Olympic Stadium used for the 1968 Olympic Games and the 1986 soccer World Cup.\n",
      "\n",
      "\tEntities: campus, buildings\n",
      "\tGold Relation: Component-Whole\n",
      "\n",
      "Extracted triples:\n"
     ]
    }
   ],
   "source": [
    "triples = []\n",
    "with StanfordOpenIE() as client:\n",
    "    for triple in client.annotate(sentence3):\n",
    "        triples.append(triple)\n",
    "        \n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence3))\n",
    "print('\\tEntities: {}, {}'.format('campus', 'buildings'))\n",
    "print('\\tGold Relation: {}\\n'.format('Component-Whole'))\n",
    "\n",
    "print(\"Extracted triples:\")\n",
    "for t in triples:\n",
    "    print(\"\\t{}\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hearst Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hearstPatterns.hearstPatterns import HearstPatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HearstPatterns(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.find_hyponyms('I am a chair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.find_hyponyms(sentence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenNRE: Neural Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import opennre\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-27 16:26:35,367 - root - INFO - Loading BERT pre-trained checkpoint.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "model = opennre.get_model('wiki80_bertentity_softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tThe man took driver's keys until the arrival of police, thus preventing him from leaving.\n",
      "\n",
      "Entities: driver, keys\n",
      "Gold Relation: Instrument-Agency\n",
      "\n",
      "Predicted Relation: ('said to be the same as', 0.11592283844947815)\n"
     ]
    }
   ],
   "source": [
    "e1 = re.search(r'driver', sentence1).span()\n",
    "e2 = re.search(r'keys', sentence1).span()\n",
    "pred = model.infer({'text': sentence1, 'h': {'pos': e1}, 't': {'pos': e2}})\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence1))\n",
    "print('Entities: {}, {}'.format('driver', 'keys'))\n",
    "print('Gold Relation: {}\\n'.format('Instrument-Agency'))\n",
    "\n",
    "print(\"Predicted Relation: {}\".format(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tAnother example is the hammered dulcimer, where the player holds the hammers.\n",
      "\n",
      "Entities: player, hammers\n",
      "Gold Relation: Entity-Origin\n",
      "\n",
      "Predicted Relation: ('instrument', 0.41270914673805237)\n"
     ]
    }
   ],
   "source": [
    "e1 = re.search(r'player', sentence2).span()\n",
    "e2 = re.search(r'hammers', sentence2).span()\n",
    "pred = model.infer({'text': sentence2, 'h': {'pos': e1}, 't': {'pos': e2}})\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence2))\n",
    "print('Entities: {}, {}'.format('player', 'hammers'))\n",
    "print('Gold Relation: {}\\n'.format('Entity-Origin'))\n",
    "\n",
    "print(\"Predicted Relation: {}\".format(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\tThe campus comprises the most noteworthy buildings including the Rector Tower, the Central Library and the University Olympic Stadium used for the 1968 Olympic Games and the 1986 soccer World Cup.\n",
      "\n",
      "Entities: campus, buildings\n",
      "Gold Relation: Component-Whole\n",
      "\n",
      "Predicted Relation: ('instance of', 0.9435627460479736)\n"
     ]
    }
   ],
   "source": [
    "e1 = re.search(r'campus', sentence3).span()\n",
    "e2 = re.search(r'buildings', sentence3).span()\n",
    "pred = model.infer({'text': sentence3, 'h': {'pos': e1}, 't': {'pos': e2}})\n",
    "\n",
    "print(\"Original text:\")\n",
    "print('\\t{}\\n'.format(sentence3))\n",
    "print('Entities: {}, {}'.format('campus', 'buildings'))\n",
    "print('Gold Relation: {}\\n'.format('Component-Whole'))\n",
    "\n",
    "print(\"Predicted Relation: {}\".format(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_to_idx = {\n",
    "    \"Cause-Effect\": 0,\n",
    "    \"Instrument-Agency\": 1,\n",
    "    \"Product-Producer\": 2,\n",
    "    \"Content-Container\": 3,\n",
    "    \"Entity-Origin\": 4,\n",
    "    \"Entity-Destination\": 5,\n",
    "    \"Component-Whole\": 6,\n",
    "    \"Member-Collection\": 7,\n",
    "    \"Message-Topic\": 8,\n",
    "    \"Other\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place served by transport hub': 0,\n",
       " 'mountain range': 1,\n",
       " 'religion': 2,\n",
       " 'participating team': 3,\n",
       " 'contains administrative territorial entity': 4,\n",
       " 'head of government': 5,\n",
       " 'country of citizenship': 6,\n",
       " 'original network': 7,\n",
       " 'heritage designation': 8,\n",
       " 'performer': 9,\n",
       " 'participant of': 10,\n",
       " 'position held': 11,\n",
       " 'has part': 12,\n",
       " 'location of formation': 13,\n",
       " 'located on terrain feature': 14,\n",
       " 'architect': 15,\n",
       " 'country of origin': 16,\n",
       " 'publisher': 17,\n",
       " 'director': 18,\n",
       " 'father': 19,\n",
       " 'developer': 20,\n",
       " 'military branch': 21,\n",
       " 'mouth of the watercourse': 22,\n",
       " 'nominated for': 23,\n",
       " 'movement': 24,\n",
       " 'successful candidate': 25,\n",
       " 'followed by': 26,\n",
       " 'manufacturer': 27,\n",
       " 'instance of': 28,\n",
       " 'after a work by': 29,\n",
       " 'member of political party': 30,\n",
       " 'licensed to broadcast to': 31,\n",
       " 'headquarters location': 32,\n",
       " 'sibling': 33,\n",
       " 'instrument': 34,\n",
       " 'country': 35,\n",
       " 'occupation': 36,\n",
       " 'residence': 37,\n",
       " 'work location': 38,\n",
       " 'subsidiary': 39,\n",
       " 'participant': 40,\n",
       " 'operator': 41,\n",
       " 'characters': 42,\n",
       " 'occupant': 43,\n",
       " 'genre': 44,\n",
       " 'operating system': 45,\n",
       " 'owned by': 46,\n",
       " 'platform': 47,\n",
       " 'tributary': 48,\n",
       " 'winner': 49,\n",
       " 'said to be the same as': 50,\n",
       " 'composer': 51,\n",
       " 'league': 52,\n",
       " 'record label': 53,\n",
       " 'distributor': 54,\n",
       " 'screenwriter': 55,\n",
       " 'sports season of league or competition': 56,\n",
       " 'taxon rank': 57,\n",
       " 'location': 58,\n",
       " 'field of work': 59,\n",
       " 'language of work or name': 60,\n",
       " 'applies to jurisdiction': 61,\n",
       " 'notable work': 62,\n",
       " 'located in the administrative territorial entity': 63,\n",
       " 'crosses': 64,\n",
       " 'original language of film or TV show': 65,\n",
       " 'competition class': 66,\n",
       " 'part of': 67,\n",
       " 'sport': 68,\n",
       " 'constellation': 69,\n",
       " 'position played on team / speciality': 70,\n",
       " 'located in or next to body of water': 71,\n",
       " 'voice type': 72,\n",
       " 'follows': 73,\n",
       " 'spouse': 74,\n",
       " 'military rank': 75,\n",
       " 'mother': 76,\n",
       " 'member of': 77,\n",
       " 'child': 78,\n",
       " 'main subject': 79}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rel2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RelationClassfication.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
